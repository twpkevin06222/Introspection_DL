{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import pickle\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import skimage.measure\n",
    "import tensorflow as tf\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "import string\n",
    "char_list = list(\" '\" + string.ascii_lowercase + '12 ')\n",
    "\n",
    "def absmax(nd_array):\n",
    "    a = np.max(np.abs(nd_array))\n",
    "    return(np.array([-a,a]))\n",
    "\n",
    "def elapsed_time(t_start,unit):\n",
    "    t_end = time.time()\n",
    "    d = t_end - t_start\n",
    "    if(unit=='min'):\n",
    "        d /= 60\n",
    "    elif(unit=='h'):\n",
    "        d /= 3600\n",
    "    print('%.2f '%d, unit + ' elapsed',sep='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"/data/asr_introspection/\"\n",
    "\n",
    "with open(data_dir + \"vocabularies.pkl\", \"rb\") as input_file:\n",
    "    graphemes_list, phonemes_list, _ = pickle.load(input_file)\n",
    "joint_list = graphemes_list + phonemes_list\n",
    "\n",
    "with open(\"/data/asr_introspection/w2l_weights.pkl\", \"rb\") as input_file:\n",
    "    weights = pickle.load(input_file)\n",
    "with open(\"/data/asr_introspection/w2l_bn_params.pkl\", \"rb\") as input_file:\n",
    "    bn_params = pickle.load(input_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute averages from one or multiple files\n",
    "with open(data_dir + 'summation_abs_actxgrad_all_noblank.pkl', 'rb') as input_file:\n",
    "    summation, n_samples = pickle.load(input_file)\n",
    "\n",
    "# normalizer (average acts/grads over all characters (only chars!))\n",
    "# should be similar to the blank label results <- check that\n",
    "normalizer = copy.deepcopy(summation)\n",
    "for layer_id in range(12):\n",
    "    for value_set in ['acts','grads']:\n",
    "        normalizer[layer_id][value_set] = np.sum(summation[layer_id][value_set][:27,:,:],0)/np.sum(n_samples[:27])\n",
    "\n",
    "# average for each character/phoneme and both for acts and grads\n",
    "averages = copy.deepcopy(summation)\n",
    "normalized_averages = copy.deepcopy(summation)\n",
    "for layer_id in range(12):\n",
    "    for char_id in range(67):\n",
    "        if(n_samples[char_id]>0):\n",
    "            for value_set in ['acts','grads']:\n",
    "                averages[layer_id][value_set][char_id,:,:] = summation[layer_id][value_set][char_id,:,:]/n_samples[char_id]\n",
    "                normalized_averages[layer_id][value_set][char_id,:,:] = averages[layer_id][value_set][char_id,:,:] - normalizer[layer_id][value_set]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_ranges = [206,80,74,68,62,56,50,44,38,32,1,1,1]\n",
    "n_filters = [256,256,256,256,256,256,256,256,256,2048,2048,31]\n",
    "receptive_field_sizes = [48,60,72,84,96,108,120,132,144,206,206,206]\n",
    "kernel_sizes = [48,7,7,7,7,7,7,7,7,32,1,1]\n",
    "strides = [2,1,1,1,1,1,1,1,1,1,1,1]\n",
    "GRIDS = {16: (4, 4), 32: (8, 4), 64: (8, 8), 128: (16, 8), 256: (16, 16),\n",
    "         512: (32, 16), 1024: (32, 32), 2048: (64, 32), 31: (31,1)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## visualize how filters look like, when neigborhood constraint is applied\n",
    "\n",
    "- all filters as huge image\n",
    "- close-up of a particular region\n",
    "- each n-th filter in each dim as a smaller filter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.5806406"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(filters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "filters = weights[0]\n",
    "filter_grid_size = GRIDS[filters.shape[2]]\n",
    "spacing = 0\n",
    "filter_plot_mat = np.zeros((filter_grid_size[0]*(filters.shape[1]+spacing),\n",
    "                            filter_grid_size[1]*(filters.shape[0]+spacing)))\n",
    "for oc in range(filters.shape[2]):\n",
    "    x_start = np.int(oc/filter_grid_size[1]) * (filters.shape[1]+spacing)\n",
    "    y_start = oc%filter_grid_size[0] * (filters.shape[0]+spacing)\n",
    "    filter_plot_mat[x_start:x_start+filters.shape[1],y_start:y_start+filters.shape[0]] = np.transpose(filters[:,:,oc])[::-1,:]\n",
    "    \n",
    "plt.figure(figsize=(20,60))\n",
    "plt.imshow(filter_plot_mat,cmap='bwr')#,aspect=filters.shape[0]/filters.shape[1])\n",
    "plt.clim(absmax(filter_plot_mat)/3)\n",
    "plt.xticks(np.arange(filters.shape[0],filter_plot_mat.shape[1],filters.shape[0]),'')\n",
    "plt.yticks(np.arange(filters.shape[1],filter_plot_mat.shape[0],filters.shape[1]),'')\n",
    "plt.grid(color='black')\n",
    "# plt.show()\n",
    "plt.savefig(figure_dir+\"regularized_filtermap.png\",\n",
    "                    dpi=100,\n",
    "                    format='png',\n",
    "                    bbox_inches='tight')\n",
    "plt.close()\n",
    "\n",
    "#close-up\n",
    "subcoords = np.stack((np.array([1,4]) * (filters.shape[1]+spacing),\n",
    "                      np.array([1,4]) * (filters.shape[0]+spacing)))\n",
    "closeup_plot_mat = filter_plot_mat[subcoords[0,0]:subcoords[0,1]-spacing,\n",
    "                           subcoords[1,0]:subcoords[1,1]-spacing]\n",
    "plt.figure(figsize=(10,20))\n",
    "plt.imshow(closeup_plot_mat,\n",
    "           cmap='bwr')#,aspect=filters.shape[0]/filters.shape[1])\n",
    "plt.clim(absmax(filter_plot_mat)/3)\n",
    "plt.xticks(np.arange(filters.shape[0],closeup_plot_mat.shape[1],filters.shape[0]),'')\n",
    "plt.yticks(np.arange(filters.shape[1],closeup_plot_mat.shape[0],filters.shape[1]),'')\n",
    "plt.grid(color='black')\n",
    "plt.title('x:'+str(subcoords[0,0])+'-'+str(subcoords[0,1])+' ; y:'+str(subcoords[1,0])+'-'+str(subcoords[1,1]))\n",
    "# plt.show()\n",
    "plt.savefig(figure_dir+\"regularized_filtermap_closeup_1.pdf\",\n",
    "                    dpi=200,\n",
    "                    format='pdf',\n",
    "                    bbox_inches='tight')\n",
    "plt.close()\n",
    "\n",
    "subcoords = np.stack((np.array([12,15]) * (filters.shape[1]+spacing),\n",
    "                      np.array([12,15]) * (filters.shape[0]+spacing)))\n",
    "closeup_plot_mat = filter_plot_mat[subcoords[0,0]:subcoords[0,1]-spacing,\n",
    "                           subcoords[1,0]:subcoords[1,1]-spacing]\n",
    "plt.figure(figsize=(10,20))\n",
    "plt.imshow(closeup_plot_mat,\n",
    "           cmap='bwr')#,aspect=filters.shape[0]/filters.shape[1])\n",
    "plt.clim(absmax(filter_plot_mat)/3)\n",
    "plt.xticks(np.arange(filters.shape[0],closeup_plot_mat.shape[1],filters.shape[0]),'')\n",
    "plt.yticks(np.arange(filters.shape[1],closeup_plot_mat.shape[0],filters.shape[1]),'')\n",
    "plt.grid(color='black')\n",
    "plt.title('x:'+str(subcoords[0,0])+'-'+str(subcoords[0,1])+' ; y:'+str(subcoords[1,0])+'-'+str(subcoords[1,1]))\n",
    "# plt.show()\n",
    "plt.savefig(figure_dir+\"regularized_filtermap_closeup_2.pdf\",\n",
    "                    dpi=200,\n",
    "                    format='pdf',\n",
    "                    bbox_inches='tight')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## grid-shaped plot of GradNAP AUCs\n",
    "- for different phonemes\n",
    "- apply avg pooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from https://stackoverflow.com/questions/42463172/how-to-perform-max-mean-pooling-on-a-2d-array-using-numpy\n",
    "\n",
    "def asStride(arr,sub_shape,stride):\n",
    "    '''Get a strided sub-matrices view of an ndarray.\n",
    "    See also skimage.util.shape.view_as_windows()\n",
    "    '''\n",
    "    s0,s1=arr.strides[:2]\n",
    "    m1,n1=arr.shape[:2]\n",
    "    m2,n2=sub_shape\n",
    "    view_shape=(1+(m1-m2)//stride[0],1+(n1-n2)//stride[1],m2,n2)+arr.shape[2:]\n",
    "    strides=(stride[0]*s0,stride[1]*s1,s0,s1)+arr.strides[2:]\n",
    "    subs=np.lib.stride_tricks.as_strided(arr,view_shape,strides=strides)\n",
    "    return subs\n",
    "\n",
    "def poolingOverlap(mat,ksize,stride=None,method='max',pad=False):\n",
    "    '''Overlapping pooling on 2D or 3D data.\n",
    "\n",
    "    <mat>: ndarray, input array to pool.\n",
    "    <ksize>: tuple of 2, kernel size in (ky, kx).\n",
    "    <stride>: tuple of 2 or None, stride of pooling window.\n",
    "              If None, same as <ksize> (non-overlapping pooling).\n",
    "    <method>: str, 'max for max-pooling,\n",
    "                   'mean' for mean-pooling.\n",
    "    <pad>: bool, pad <mat> or not. If no pad, output has size\n",
    "           (n-f)//s+1, n being <mat> size, f being kernel size, s stride.\n",
    "           if pad, output has size ceil(n/s).\n",
    "\n",
    "    Return <result>: pooled matrix.\n",
    "    '''\n",
    "\n",
    "    m, n = mat.shape[:2]\n",
    "    ky,kx=ksize\n",
    "    if stride is None:\n",
    "        stride=(ky,kx)\n",
    "    sy,sx=stride\n",
    "\n",
    "    _ceil=lambda x,y: int(np.ceil(x/float(y)))\n",
    "\n",
    "    if pad:\n",
    "        ny=_ceil(m,sy)\n",
    "        nx=_ceil(n,sx)\n",
    "        size=((ny-1)*sy+ky, (nx-1)*sx+kx) + mat.shape[2:]\n",
    "        mat_pad=np.full(size,np.nan)\n",
    "        mat_pad[:m,:n,...]=mat\n",
    "    else:\n",
    "        mat_pad=mat[:(m-ky)//sy*sy+ky, :(n-kx)//sx*sx+kx, ...]\n",
    "\n",
    "    view=asStride(mat_pad,ksize,stride)\n",
    "\n",
    "    if method=='max':\n",
    "        result=np.nanmax(view,axis=(2,3))\n",
    "    else:\n",
    "        result=np.nanmean(view,axis=(2,3))\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'AA'"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joint_list[28]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "plot saved\n",
      "plot saved\n",
      "plot saved\n",
      "plot saved\n",
      "plot saved\n",
      "plot saved\n",
      "plot saved\n",
      "plot saved\n",
      "plot saved\n",
      "plot saved\n",
      "plot saved\n"
     ]
    }
   ],
   "source": [
    "# layer_id = 1  # 0 would be the input\n",
    "char_id = 29  # /AE/\n",
    "layers = np.arange(1,12)\n",
    "responsive_neuron_ids = [dict() for i in range(12)]\n",
    "\n",
    "figure_dir = \"/project/asr_introspection/figures/\"\n",
    "fig_format = \"pdf\"\n",
    "\n",
    "for layer_id in layers:\n",
    "    if(layer_id<10):\n",
    "        fig = plt.figure(figsize=(6,9))\n",
    "    else:\n",
    "        fig = plt.figure(figsize=(6,18))\n",
    "    grid = plt.GridSpec(3,2, hspace=0, wspace=0)\n",
    "    \n",
    "    for i, char_id in enumerate([28,29,58]):\n",
    "\n",
    "        gradNAP = normalized_averages[layer_id]['acts'][char_id]\n",
    "\n",
    "        AUC = np.sum(np.abs(gradNAP),1)\n",
    "        AUC = np.sign(np.mean(gradNAP,1)) * AUC\n",
    "\n",
    "#         absmax_sign = np.sign(np.max(gradNAP,1) + np.min(gradNAP,1))\n",
    "#         AUC = absmax_sign * np.max(np.abs(gradNAP),1)\n",
    "        \n",
    "    \n",
    "#         AUC_reshaped = np.reshape(AUC,GRIDS[AUC.shape[0]])\n",
    "        AUC_reshaped = np.transpose(np.reshape(AUC,GRIDS[AUC.shape[0]][::-1]))\n",
    "        \n",
    "\n",
    "#         k_dimfactor = 4\n",
    "#         ksize = (np.int(AUC_reshaped.shape[0]/k_dimfactor),\n",
    "#                  np.int(AUC_reshaped.shape[1]/k_dimfactor))\n",
    "        if(layer_id<10):    \n",
    "            ksize = (3,3)\n",
    "        else:\n",
    "            ksize = (3,3)\n",
    "        avg_pooled_AUC = poolingOverlap(mat = AUC_reshaped,\n",
    "                                        ksize = ksize,\n",
    "                                        stride = (1,1),\n",
    "                                        method = 'mean',\n",
    "                                        pad = False)\n",
    "#         skimage.measure.block_reduce(AUC_reshaped, (3,3), np.mean)\n",
    "        \n",
    "        \n",
    "        responsive_region_idx = np.argmax(np.abs(avg_pooled_AUC))\n",
    "        responsive_x = responsive_region_idx%avg_pooled_AUC.shape[1]\n",
    "        responsive_y = np.int(responsive_region_idx/avg_pooled_AUC.shape[1])\n",
    "        \n",
    "        \n",
    "        helper_mat = copy.deepcopy(AUC_reshaped)\n",
    "        helper_mat[responsive_y:responsive_y+ksize[1],responsive_x:responsive_x+ksize[0]] = np.max(helper_mat)+1\n",
    "        neuron_ids = np.sort(np.argsort(np.concatenate(np.transpose(helper_mat)))[::-1][:np.prod(ksize)])\n",
    "        neuron_ids = neuron_ids * np.sign(AUC[neuron_ids]).astype('int')\n",
    "        responsive_neuron_ids[layer_id][joint_list[char_id]] = neuron_ids\n",
    "        \n",
    "        ax = fig.add_subplot(grid[i,0])\n",
    "#         ax = plt.subplot(2,3,i+1)\n",
    "        plt.imshow(AUC_reshaped,cmap='bwr')\n",
    "        plt.clim(absmax(AUC))\n",
    "        plt.xlim([-1.5,AUC_reshaped.shape[1]+0.5])\n",
    "        plt.ylim([-1.5,AUC_reshaped.shape[0]+0.5])\n",
    "        plt.axis('off')\n",
    "\n",
    "        rect = mpl.patches.Rectangle((-0.5,-0.5),AUC_reshaped.shape[1],AUC_reshaped.shape[0],linewidth=1,edgecolor='#000000',facecolor='none')\n",
    "        ax.add_patch(rect) \n",
    "        rect = mpl.patches.Rectangle((responsive_x-0.5,responsive_y-0.5),ksize[1],ksize[0],linewidth=3,edgecolor='#00ff00',facecolor='none')\n",
    "        ax.add_patch(rect)  \n",
    "        \n",
    "        avg_pooled_AUC = np.pad(avg_pooled_AUC, 1, 'constant', constant_values=0)\n",
    "        \n",
    "        ax = fig.add_subplot(grid[i,1])\n",
    "#         ax = plt.subplot(2,3,i+4)\n",
    "        plt.imshow(avg_pooled_AUC,cmap='bwr')\n",
    "        plt.clim(absmax(avg_pooled_AUC))\n",
    "        plt.xlim([-1.5,avg_pooled_AUC.shape[1]+0.5])\n",
    "        plt.ylim([-1.5,avg_pooled_AUC.shape[0]+0.5])\n",
    "        plt.axis('off')\n",
    "        \n",
    "        rect = mpl.patches.Rectangle((0.5,0.5),avg_pooled_AUC.shape[1]-2,avg_pooled_AUC.shape[0]-2,linewidth=1,edgecolor='#000000',facecolor='none')\n",
    "        ax.add_patch(rect) \n",
    "        rect = mpl.patches.Rectangle((responsive_x+0.5,responsive_y+0.5),1,1,linewidth=3,edgecolor='#00ff00',facecolor='none')\n",
    "        ax.add_patch(rect)   \n",
    "        \n",
    "    plt.savefig(figure_dir + \"responsive_regions_layer\"+str(layer_id)+\".\"+fig_format,\n",
    "                dpi=300,\n",
    "                format=fig_format,\n",
    "                bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(\"plot saved\")\n",
    "#     plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## feature vis for active GradNAP AUC plot regions\n",
    "- for different phonemes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def build_dict(layer_id, input_tensor, weights, bn_params):\n",
    "    d = dict()\n",
    "#     d[input_tensor]=[np.transpose(spec)]\n",
    "    \n",
    "    if layer_id==11:\n",
    "        d['out/bias:0'] = weights[11]\n",
    "        d['out/kernel:0'] = weights[12]\n",
    "        layer_id -= 1\n",
    "    \n",
    "    for i in np.arange(layer_id+1):\n",
    "        d['conv_'+str(i)+'/kernel:0'] = weights[i]\n",
    "        d['batch_norm_'+str(i)+'/beta:0'] = bn_params[(i*4)]\n",
    "        d['batch_norm_'+str(i)+'/gamma:0'] = bn_params[(i*4)+1]\n",
    "        d['batch_norm_'+str(i)+'/moving_mean:0'] = bn_params[(i*4)+2]\n",
    "        d['batch_norm_'+str(i)+'/moving_variance:0'] = bn_params[(i*4)+3]\n",
    "    \n",
    "    return d\n",
    "\n",
    "def conv_layer(inputs, n_filter, kernel_size, stride, layer_id, out_layer=False):\n",
    "    if(not out_layer):\n",
    "        conv = tf.layers.conv1d(\n",
    "            inputs = inputs, \n",
    "            filters = n_filter, \n",
    "            kernel_size = kernel_size,\n",
    "            strides=stride, \n",
    "            activation=None,\n",
    "            use_bias=False, \n",
    "            padding=\"valid\",\n",
    "            name=\"conv_\"+str(layer_id),\n",
    "            data_format=\"channels_last\",\n",
    "            trainable=False)\n",
    "\n",
    "        conv_bn = tf.layers.batch_normalization(\n",
    "            conv, \n",
    "            axis=2, \n",
    "            training=False, \n",
    "            name=\"batch_norm_\"+str(layer_id),\n",
    "            trainable=False)\n",
    "\n",
    "        relu_out = tf.nn.relu(conv_bn)\n",
    "\n",
    "        return(conv_bn,relu_out)\n",
    "    else:\n",
    "        conv = tf.layers.conv1d(\n",
    "            inputs = inputs, \n",
    "            filters = n_filter, \n",
    "            kernel_size = kernel_size,\n",
    "            strides=stride, \n",
    "            activation=None,\n",
    "            use_bias=True, \n",
    "            padding=\"valid\",\n",
    "            name=\"out\",\n",
    "            data_format=\"channels_last\",\n",
    "            trainable=False)\n",
    "\n",
    "        return(conv)\n",
    "\n",
    "def build_w2l_model(weights,bn_params,layer_id,filter_ids):\n",
    "    tf.reset_default_graph()\n",
    "\n",
    "    n_filters = [256,256,256,256,256,256,256,256,256,2048,2048,31]\n",
    "    kernel_sizes = [48,7,7,7,7,7,7,7,7,32,1,1]\n",
    "    strides = [2,1,1,1,1,1,1,1,1,1,1,1]\n",
    "    GRIDS = {16: (4, 4), 32: (8, 4), 64: (8, 8), 128: (16, 8), 256: (16, 16),\n",
    "             512: (32, 16), 1024: (32, 32), 2048: (64, 32), 31: (31,1)}\n",
    "    receptive_field_sizes = [48,60,72,84,96,108,120,132,144,206,206,206]\n",
    "    \n",
    "    x = tf.get_variable(\"x\", [1,206,128], dtype=tf.float32,\n",
    "                        initializer = tf.initializers.random_normal(mean=0,stddev=0.001))\n",
    "#     x = 5 * (x / tf.reduce_max(tf.abs(x)) )  # spectrogram data is in the range [-4.98,4.64]\n",
    "    \n",
    "    x_perturbated = tf.concat([x for i in range(5)],0) #input robust to n random perturbations\n",
    "    x_perturbated = x_perturbated + tf.random_normal(tf.shape(x_perturbated),mean=0,stddev=0.05)\n",
    "\n",
    "    layer_outs = []\n",
    "    pre_activations = []\n",
    "    p,l = conv_layer(x_perturbated,n_filters[0],kernel_sizes[0],strides[0],0)\n",
    "    pre_activations.append(p)\n",
    "    layer_outs.append(l)\n",
    "\n",
    "    for i in np.arange(11)[1:]:\n",
    "        p,l = conv_layer(layer_outs[i-1],n_filters[i],kernel_sizes[i],strides[i],i)\n",
    "        pre_activations.append(p)\n",
    "        layer_outs.append(l)\n",
    "\n",
    "    pre_activations.append(conv_layer(layer_outs[10],n_filters[11],kernel_sizes[11],strides[11],11,out_layer=True))\n",
    "    layer_outs.append(tf.nn.softmax(pre_activations[11]))\n",
    "    \n",
    "#     loss = layer_outs[layer_id][:,tf.cast(tf.floor(tf.shape(layer_outs[layer_id])[1]/2),tf.int32),:]\n",
    "#     loss = layer_outs[layer_id][:,0,:]\n",
    "#     loss = tf.reduce_sum(np.sign(filter_ids)*(-1)*tf.reduce_sum(tf.gather(loss,np.abs(filter_ids),axis=1),axis=0))\n",
    "    \n",
    "    opt_target = pre_activations[layer_id][:,0,:]\n",
    "    loss = (-1)*tf.reduce_sum(tf.gather(opt_target,np.abs(filter_ids),axis=1),axis=0)\n",
    "    loss = tf.reduce_sum(np.sign(filter_ids)*loss)\n",
    "    \n",
    "    non_responsives_sum = tf.reduce_sum(tf.gather(tf.abs(opt_target),\n",
    "                                                  np.setdiff1d(np.arange(n_filters[layer_id]),\n",
    "                                                               np.abs(filter_ids)),\n",
    "                                                  axis=1),\n",
    "                                        axis=0)\n",
    "    sparsity_loss = 0*tf.reduce_sum(tf.abs(non_responsives_sum))\n",
    "    loss = loss + sparsity_loss\n",
    "    \n",
    "    \n",
    "    \n",
    "    # regularization parameters dependent on width of receptive field in the respective layer\n",
    "    loss = loss + tf.contrib.layers.apply_regularization(\n",
    "        regularizer=tf.contrib.layers.l1_l2_regularizer(15 / receptive_field_sizes[layer_id],\n",
    "                                                        0.1 / receptive_field_sizes[layer_id]),\n",
    "        weights_list=[x]\n",
    "    )\n",
    "    \n",
    "    \n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate=0.05)\n",
    "    train_op = optimizer.minimize(\n",
    "        loss=loss,\n",
    "        global_step=tf.train.get_global_step())\n",
    "    \n",
    "    return([train_op,x,loss,sparsity_loss,opt_target])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "plot saved\n",
      "plot saved\n",
      "plot saved\n",
      "plot saved\n",
      "plot saved\n",
      "plot saved\n",
      "plot saved\n",
      "plot saved\n",
      "plot saved\n",
      "plot saved\n",
      "plot saved\n"
     ]
    }
   ],
   "source": [
    "receptive_field_sizes = [48,60,72,84,96,108,120,132,144,206,206,206]\n",
    "GRIDS = {16: (4, 4), 32: (8, 4), 64: (8, 8), 128: (16, 8), 256: (16, 16),\n",
    "             512: (32, 16), 1024: (32, 32), 2048: (64, 32), 31: (31,1)}\n",
    "n_steps = 16\n",
    "print_each = 0#np.int(n_steps/5)\n",
    "n_repetitions = 1\n",
    "layers = np.arange(1,12)\n",
    "character_ids = [28,29,58]#np.arange(len(joint_list))\n",
    "\n",
    "# create region-wise optimal inputs\n",
    "for layer_id in layers:\n",
    "    fig = plt.figure(figsize=(5,15))\n",
    "    grid = plt.GridSpec(3,1, hspace=0.1, wspace=0)\n",
    "    for idx, char_id in enumerate(character_ids):\n",
    "        # for neuron_id in range(len(responsive_neuron_ids[layer_id])):\n",
    "        tf.reset_default_graph()\n",
    "        char_responsive_neurons = responsive_neuron_ids[layer_id][joint_list[char_id]]\n",
    "        ops = build_w2l_model(weights, bn_params, layer_id, char_responsive_neurons\n",
    "        #                           [neuron_id:neuron_id+1]\n",
    "                             )\n",
    "        mean_optimal_input = np.zeros([1,206,128])\n",
    "        with tf.Session() as sess:\n",
    "            init = tf.global_variables_initializer()\n",
    "            sess.run(init)\n",
    "\n",
    "            d = build_dict(11,None,weights,bn_params)\n",
    "            for i in range(n_steps):\n",
    "                _, optimal_input,_,_, opt_target = sess.run(ops,feed_dict=d)\n",
    "        \n",
    "        ax = fig.add_subplot(grid[idx])\n",
    "        plt.imshow(np.transpose(optimal_input[0,:receptive_field_sizes[layer_id],::-1]),cmap='bwr')\n",
    "        plt.clim(absmax(optimal_input))\n",
    "        plt.axis('off')\n",
    "        rect = mpl.patches.Rectangle((-0.5,-0.5),receptive_field_sizes[layer_id],optimal_input.shape[2],linewidth=1,edgecolor='#000000',facecolor='none')\n",
    "        ax.add_patch(rect) \n",
    "        \n",
    "    plt.savefig(figure_dir + \"joint_featurevis_layer\"+str(layer_id)+\".\"+fig_format,\n",
    "                dpi=300,\n",
    "                format=fig_format,\n",
    "                bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(\"plot saved\")\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "plot saved\n",
      "plot saved\n",
      "plot saved\n",
      "plot saved\n",
      "plot saved\n",
      "plot saved\n",
      "plot saved\n",
      "plot saved\n",
      "plot saved\n",
      "plot saved\n",
      "plot saved\n",
      "plot saved\n",
      "plot saved\n",
      "plot saved\n",
      "plot saved\n",
      "plot saved\n",
      "plot saved\n",
      "plot saved\n",
      "plot saved\n",
      "plot saved\n",
      "plot saved\n",
      "plot saved\n",
      "plot saved\n",
      "plot saved\n",
      "plot saved\n",
      "plot saved\n",
      "plot saved\n",
      "plot saved\n",
      "plot saved\n",
      "plot saved\n",
      "plot saved\n"
     ]
    }
   ],
   "source": [
    "receptive_field_sizes = [48,60,72,84,96,108,120,132,144,206,206,206]\n",
    "GRIDS = {16: (4, 4), 32: (8, 4), 64: (8, 8), 128: (16, 8), 256: (16, 16),\n",
    "             512: (32, 16), 1024: (32, 32), 2048: (64, 32), 31: (31,1)}\n",
    "n_steps = 16\n",
    "print_each = 0#np.int(n_steps/5)\n",
    "n_repetitions = 1\n",
    "layers = np.arange(1,12)\n",
    "character_ids = [28,29,58]#np.arange(len(joint_list))\n",
    "\n",
    "# create region-wise optimal inputs\n",
    "for layer_id in layers:\n",
    "    for idx, char_id in enumerate(character_ids):\n",
    "        fig = plt.figure(figsize=(8,15))\n",
    "        grid = plt.GridSpec(3,3, hspace=0.05, wspace=0.05,)\n",
    "        \n",
    "        for grid_idx, responsive_neuron in enumerate(responsive_neuron_ids[layer_id][joint_list[char_id]]):\n",
    "            tf.reset_default_graph()\n",
    "            ops = build_w2l_model(weights, bn_params, layer_id, [responsive_neuron])\n",
    "            mean_optimal_input = np.zeros([1,206,128])\n",
    "            with tf.Session() as sess:\n",
    "                init = tf.global_variables_initializer()\n",
    "                sess.run(init)\n",
    "\n",
    "                d = build_dict(11,None,weights,bn_params)\n",
    "                for i in range(n_steps):\n",
    "                    _, optimal_input,_,_, opt_target = sess.run(ops,feed_dict=d)\n",
    "\n",
    "            ax = fig.add_subplot(grid[grid_idx%3,np.int(grid_idx/3)])\n",
    "            plt.imshow(np.transpose(optimal_input[0,:receptive_field_sizes[layer_id],::-1]),cmap='bwr')\n",
    "            plt.clim(absmax(optimal_input))\n",
    "            plt.axis('off')\n",
    "            rect = mpl.patches.Rectangle((-0.5,-0.5),receptive_field_sizes[layer_id],optimal_input.shape[2],linewidth=1,edgecolor='#000000',facecolor='none')\n",
    "            ax.add_patch(rect) \n",
    "\n",
    "        plt.savefig(figure_dir + \"single_featurevis_layer\"+str(layer_id)+\"_phoneme_\"+joint_list[char_id]+\".\"+fig_format,\n",
    "                    dpi=300,\n",
    "                    format=fig_format,\n",
    "                    bbox_inches='tight')\n",
    "        plt.close()\n",
    "        print(\"plot saved\")\n",
    "#         plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #longer set of different plots\n",
    "\n",
    "\n",
    "# for layer_id in layers:\n",
    "#     for char_id in character_ids:\n",
    "#         # for neuron_id in range(len(responsive_neuron_ids[layer_id])):\n",
    "#         tf.reset_default_graph()\n",
    "#         char_responsive_neurons = responsive_neuron_ids[layer_id][joint_list[char_id]]\n",
    "#         ops = build_w2l_model(weights, bn_params, layer_id, char_responsive_neurons\n",
    "#         #                           [neuron_id:neuron_id+1]\n",
    "#                              )\n",
    "#         mean_optimal_input = np.zeros([1,206,128])\n",
    "#         with tf.Session() as sess:\n",
    "#             init = tf.global_variables_initializer()\n",
    "#             sess.run(init)\n",
    "\n",
    "#             d = build_dict(11,None,weights,bn_params)\n",
    "#             loss_curve = list()\n",
    "#             sparsity_loss_curve = list()\n",
    "#             for i in range(n_steps):\n",
    "#                 _, optimal_input,tracking_loss,sparsity_loss, opt_target = sess.run(ops,feed_dict=d)\n",
    "#                 loss_curve.append(tracking_loss)\n",
    "#                 sparsity_loss_curve.append(sparsity_loss)\n",
    "\n",
    "#         # plt.plot(np.array(loss_curve),'-')\n",
    "#         # plt.show()\n",
    "\n",
    "#         # plt.plot(np.array(loss_curve)-np.array(sparsity_loss_curve),'-')\n",
    "#         # plt.show()\n",
    "\n",
    "#         # plt.plot(np.array(sparsity_loss_curve),'-')\n",
    "#         # plt.show()\n",
    "\n",
    "#         plt.imshow(np.transpose(optimal_input[0,:receptive_field_sizes[layer_id],::-1]),cmap='bwr')\n",
    "#         plt.clim(absmax(optimal_input))\n",
    "#         plt.show()\n",
    "\n",
    "#         responsive_neurons_mat = np.repeat(0,opt_target.shape[1])\n",
    "#         responsive_neurons_mat[np.abs(char_responsive_neurons\n",
    "#         #                                   [neuron_id:neuron_id+1]\n",
    "#                                      )] = np.sign(char_responsive_neurons\n",
    "#         #                                               [neuron_id:neuron_id+1]\n",
    "#                                                  )\n",
    "# #         plt.imshow(np.transpose(np.reshape(responsive_neurons_mat,GRIDS[opt_target.shape[1]][::-1])),cmap='bwr')\n",
    "# #         plt.clim(absmax(responsive_neurons_mat))\n",
    "# #         plt.xticks(np.arange(GRIDS[opt_target.shape[1]][0])-0.5,\"\")\n",
    "# #         plt.yticks(np.arange(GRIDS[opt_target.shape[1]][1])-0.5,\"\")\n",
    "# #         plt.grid()\n",
    "# #         plt.show()\n",
    "\n",
    "# #         plt.imshow(np.transpose(np.reshape(opt_target[0,:],GRIDS[opt_target.shape[1]][::-1])),cmap='bwr')\n",
    "# #         plt.clim(absmax(opt_target))\n",
    "# #         plt.xticks(np.arange(GRIDS[opt_target.shape[1]][0])-0.5,\"\")\n",
    "# #         plt.yticks(np.arange(GRIDS[opt_target.shape[1]][1])-0.5,\"\")\n",
    "# #         plt.grid()\n",
    "# #         plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
