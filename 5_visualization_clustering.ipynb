{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This NB is visualizing the aligned and averaged Inputs/NAPs  \n",
    "To this end we perform:\n",
    "- visualization of GradNAvAI (gradient-weighted normalized averaging of aligned inputs), which is basically a GradNAP o the input\n",
    "- clustering of GradNAPs in each layer for phonemes and graphemes respectively\n",
    "- ERP curves of filters of highest activation (GradNAPs as line plots)\n",
    "- featurevis(AM) for the filters of the ERP approach (maybe sets of neurons?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import pickle\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.metrics.pairwise import pairwise_distances\n",
    "from scipy.cluster import hierarchy\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "import string\n",
    "char_list = list(\" '\" + string.ascii_lowercase + '12 ')\n",
    "\n",
    "def absmax(nd_array):\n",
    "    a = np.max(np.abs(nd_array))\n",
    "    return((-a,a))\n",
    "\n",
    "def elapsed_time(t_start,unit):\n",
    "    t_end = time.time()\n",
    "    d = t_end - t_start\n",
    "    if(unit=='min'):\n",
    "        d /= 60\n",
    "    elif(unit=='h'):\n",
    "        d /= 3600\n",
    "    print('%.2f '%d, unit + ' elapsed',sep='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"/data/asr_introspection/\"\n",
    "\n",
    "with open(data_dir + \"vocabularies.pkl\", \"rb\") as input_file:\n",
    "    graphemes_list, phonemes_list, _ = pickle.load(input_file)\n",
    "joint_list = graphemes_list + phonemes_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute averages from one or multiple files\n",
    "with open(data_dir + 'summation_abs_actxgrad_all_noblank.pkl', 'rb') as input_file:\n",
    "    summation, n_samples = pickle.load(input_file)\n",
    "\n",
    "# normalizer (average acts/grads over all characters (only chars!))\n",
    "# should be similar to the blank label results <- check that\n",
    "normalizer = copy.deepcopy(summation)\n",
    "for layer_id in range(12):\n",
    "    for value_set in ['acts','grads']:\n",
    "        normalizer[layer_id][value_set] = np.sum(summation[layer_id][value_set][:27,:,:],0)/np.sum(n_samples[:27])\n",
    "\n",
    "# average for each character/phoneme and both for acts and grads\n",
    "averages = copy.deepcopy(summation)\n",
    "normalized_averages = copy.deepcopy(summation)\n",
    "for layer_id in range(12):\n",
    "    for char_id in range(67):\n",
    "        if(n_samples[char_id]>0):\n",
    "            for value_set in ['acts','grads']:\n",
    "                averages[layer_id][value_set][char_id,:,:] = summation[layer_id][value_set][char_id,:,:]/n_samples[char_id]\n",
    "                normalized_averages[layer_id][value_set][char_id,:,:] = averages[layer_id][value_set][char_id,:,:] - normalizer[layer_id][value_set]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a - 32624 samples\n"
     ]
    }
   ],
   "source": [
    "def draw_heatmap_on_axis(plot_mat, axes, row_id, col_id, cmap_type, aspect):\n",
    "    if cmap_type=='div':\n",
    "        cmap = plt.cm.bwr\n",
    "    else:\n",
    "        cmap = mpl.colors.LinearSegmentedColormap.from_list(\"whitered\", [(1,1,1),(1,0,0)] , N=100)\n",
    "    heatmap = axes[row_id,col_id].pcolor(plot_mat, cmap=cmap)\n",
    "    axes[row_id,col_id].set_aspect(aspect)\n",
    "    #fig.colorbar(heatmap,ax=axes[row_id,col_id],orientation=cbar_orientation)\n",
    "    clim = absmax(plot_mat)\n",
    "    if cmap_type=='seq': clim=(0,clim[1])\n",
    "    heatmap.set_clim(clim)\n",
    "\n",
    "def get_responsive_units(act_mat, n_top, absolute=False):\n",
    "    if(absolute):\n",
    "        abs_act_mat = np.abs(act_mat)\n",
    "        AUC_estimate = np.sum(abs_act_mat,1)\n",
    "        responsive_units = np.argsort(AUC_estimate)[::-1][:n_top]\n",
    "        responsive_units = (np.sign(np.sum(act_mat,1))[responsive_units] * responsive_units).astype('int32')\n",
    "    else:\n",
    "        neg_act_mat = copy.deepcopy(act_mat)\n",
    "        neg_act_mat[neg_act_mat>0] = 0\n",
    "        neg_AUC_estimate = -1*np.sum(neg_act_mat,1)\n",
    "        pos_act_mat = copy.deepcopy(act_mat)\n",
    "        pos_act_mat[pos_act_mat<0] = 0\n",
    "        pos_AUC_estimate = np.sum(pos_act_mat,1)\n",
    "        responsive_units = np.concatenate((np.argsort(pos_AUC_estimate)[::-1][:n_top],\n",
    "                                           np.argsort(neg_AUC_estimate)[::-1][:n_top]))\n",
    "    return(responsive_units)\n",
    "\n",
    "def steps_to_seconds(s):\n",
    "    return((s*206)/2.075)\n",
    "\n",
    "layers = [1,2]#np.arange(12)\n",
    "layer_ranges = [206,80,74,68,62,56,50,44,38,32,1,1,1]\n",
    "n_rows = 2\n",
    "character_id_list = [1]#np.arange(len(joint_list))\n",
    "n_responsive_units = 5\n",
    "responsive_units_array = np.zeros((len(joint_list),len(layers),n_responsive_units),dtype='int32')\n",
    "\n",
    "\n",
    "figure_dir = \"/project/asr_introspection/figures/\"\n",
    "fig_format = \"svg\"\n",
    "\n",
    "do_values_plots = True\n",
    "if(do_values_plots):\n",
    "    for char_id in character_id_list:\n",
    "        print(joint_list[char_id] + \" - \" + str(n_samples[char_id]) + \" samples\")\n",
    "        fig, axes = plt.subplots(nrows=n_rows, ncols=len(layers), figsize=(len(layers)*4,n_rows*5.5))\n",
    "        for col_id, layer_id in enumerate(layers):\n",
    "            cbar_orientation = 'vertical'\n",
    "            if(layer_id==0):\n",
    "                cbar_orientation = 'horizontal'\n",
    "\n",
    "            acts = normalized_averages[layer_id]['grads'][char_id,:,:]\n",
    "            norm_acts = normalized_averages[layer_id]['acts'][char_id,:,:]\n",
    "            absgrads = averages[layer_id]['grads'][char_id,:,:]\n",
    "            gradNAP = np.zeros_like(norm_acts)\n",
    "            if(n_samples[char_id]>0):\n",
    "                gradient_mask = np.abs(absgrads) / np.max(np.abs(absgrads))\n",
    "                gradNAP = norm_acts * gradient_mask\n",
    "\n",
    "\n",
    "            aspect = (1 if layer_id<10 else 1/50)\n",
    "            #draw_heatmap_on_axis(acts,axes,0,col_id,'div',aspect)\n",
    "            draw_heatmap_on_axis(norm_acts,axes,0,col_id,'div',aspect)\n",
    "#             draw_heatmap_on_axis(absgrads,axes,2,col_id,'seq',aspect)\n",
    "            draw_heatmap_on_axis(gradNAP,axes,1,col_id,'div',aspect)\n",
    "\n",
    "        plt.tight_layout()\n",
    "#         plt.show()\n",
    "        plt.savefig(figure_dir + \"gradNAP_plots_char_\"+joint_list[char_id]+\".\"+fig_format,\n",
    "                    dpi=300,\n",
    "                    format=fig_format,\n",
    "                    bbox_inches='tight')\n",
    "        plt.close()\n",
    "\n",
    "do_lineplots = False\n",
    "if(do_lineplots):\n",
    "    for char_id in character_id_list:\n",
    "        fig = plt.figure(figsize=(80,8))\n",
    "        grid = plt.GridSpec(1, len(layers)-3, hspace=0.2, wspace=0.2, width_ratios=np.array(layer_ranges[1:10])/32)\n",
    "        print(joint_list[char_id] + \" - \" + str(n_samples[char_id]) + \" samples\")\n",
    "        for col_id, layer_id in enumerate(layers):\n",
    "            norm_acts = normalized_averages[layer_id]['acts'][char_id,:,:]\n",
    "            absgrads = averages[layer_id]['grads'][char_id,:,:]\n",
    "            gradNAP = np.zeros_like(norm_acts)\n",
    "            if(n_samples[char_id]>0):\n",
    "                gradient_mask = np.abs(absgrads) / np.max(np.abs(absgrads))\n",
    "                gradNAP = norm_acts * gradient_mask\n",
    "            gradNAP = gradNAP*1000 #np.max(np.abs(gradNAP))\n",
    "            \n",
    "            responsive_units = get_responsive_units(gradNAP,n_responsive_units,absolute=True)\n",
    "            responsive_units_array[char_id,col_id,:] = responsive_units\n",
    "            responsive_gradNAP = copy.deepcopy(gradNAP)\n",
    "            responsive_gradNAP[np.abs(responsive_units),:] *= 100\n",
    "\n",
    "            if(col_id>0 and col_id<10):\n",
    "    #             plt.subplot(1,len(layers)-3,col_id)\n",
    "                ax = fig.add_subplot(grid[col_id-1])\n",
    "                center = np.int(layer_ranges[col_id]/2)\n",
    "                l = mpl.lines.Line2D([center,center],[-10,10],color=\"grey\",linestyle=\"dashed\")\n",
    "                ax.add_line(l)\n",
    "                plt.plot(np.transpose(gradNAP),'-',color='black',alpha=0.05)\n",
    "                plt.plot(np.transpose(gradNAP[np.abs(responsive_units),:]),'-')\n",
    "                plt.xlabel('time (s)')\n",
    "                plt.ylabel('gradient-adjusted activation ($10^{-3}$)')\n",
    "#                 plt.yticks(np.arange(-1,1.01,0.25))\n",
    "                plt.ylim(np.array(absmax(gradNAP))*1.1)\n",
    "#                 plt.ylim(np.array([np.min(gradNAP),np.max(gradNAP)])*1.1)\n",
    "                step_width = steps_to_seconds(0.1)\n",
    "                xtick_pos = np.arange(center-(3*step_width),center+1+(3*step_width),step_width)\n",
    "                xtick_labels = [\"-0.6\",\"-0.4\",\"-0.2\",\"0\",\"+0.2\",\"+0.4\",\"+0.6\"]\n",
    "                plt.xticks(xtick_pos,xtick_labels)\n",
    "                plt.xlim((0,layer_ranges[col_id]-1))\n",
    "                plt.grid(linestyle='dotted')\n",
    "\n",
    "#         plt.show()\n",
    "        plt.savefig(figure_dir + \"activation_line_plot_char_\"+joint_list[char_id]+\".\"+fig_format,\n",
    "                    dpi=300,\n",
    "                    format=fig_format,\n",
    "                    bbox_inches='tight')\n",
    "        plt.close()\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.075"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((400+(205*160))/16000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "2.075  0.25\n",
    "  206"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24.819277108433734"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(0.25*206)/2.075"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 2048)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.transpose(gradNAP).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('/data/asr_introspection/responsive_units_array_signed.npy',responsive_units_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# clustering based on gradNAPs\n",
    "\n",
    "def plot_cluster_heatmap_on_gridspec(profile_values, labels, cluster_metric, linkage_method, score_percentile, gs, gs_from, clim, rotate_x, plot_colorbar):\n",
    "    distance_mat = pairwise_distances(profile_values,metric=cluster_metric)\n",
    "    linkage = hierarchy.linkage(profile_values, metric=cluster_metric, method=linkage_method, optimal_ordering=False)\n",
    "    dendrogram_order = np.asarray(hierarchy.dendrogram(linkage,no_plot=True)['leaves'],dtype='int32')[::-1]\n",
    "    \n",
    "    plt.subplot(gs[gs_from])\n",
    "    hierarchy.dendrogram(linkage,orientation='left',\n",
    "                         no_labels=True,\n",
    "                         color_threshold=np.percentile(linkage[:,2],score_percentile))\n",
    "    plt.axis('off')\n",
    "\n",
    "    ax = plt.subplot(gs[gs_from+1])\n",
    "    plt.imshow(distance_mat[dendrogram_order,:][:,dendrogram_order[::-1]],cmap='hot')\n",
    "    plt.clim(clim)\n",
    "    sorted_chars = []\n",
    "    sorted_chars.extend(labels)\n",
    "    sorted_chars = np.asarray(sorted_chars)[dendrogram_order]\n",
    "    ax.xaxis.set_ticks(range(len(sorted_chars)))\n",
    "    ax.xaxis.set_ticklabels(sorted_chars[::-1])\n",
    "    plt.xticks(fontsize=8)\n",
    "    if(rotate_x):\n",
    "        plt.xticks(rotation=90)\n",
    "    ax.yaxis.set_ticks(range(len(sorted_chars)))\n",
    "    ax.yaxis.set_ticklabels(sorted_chars)\n",
    "    plt.yticks(fontsize=8)\n",
    "    ax.yaxis.tick_left()\n",
    "    \n",
    "    if(plot_colorbar):\n",
    "        plt.subplot(gs[gs_from+2])\n",
    "        mpb = plt.imshow([[clim[1]+1]],cmap='hot')\n",
    "        plt.axis('off')\n",
    "        plt.clim(clim)\n",
    "        plt.colorbar()\n",
    "\n",
    "def plot_cluster_heatmaps(profile_values_list, labels_list, cluster_metric='euclidean', linkage_method='complete', score_percentile=80, figure_dir=None, layer_id=None, fig_format='png'):\n",
    "    if(len(profile_values_list)!=len(labels_list)):\n",
    "        raise ValueError(\"list of profile values (\" + str(len(profile_values_list)) + \") must be of same length as list of label sets (\" + str(len(labels_list)) + \")\")\n",
    "    n_profiles = len(profile_values_list)\n",
    "    \n",
    "    clim=[0,0]\n",
    "    for profile in profile_values_list:\n",
    "        distance_mat = pairwise_distances(profile,metric=cluster_metric)\n",
    "        if(clim[1] < np.max(distance_mat)):\n",
    "            clim[1] = np.max(distance_mat)\n",
    "    \n",
    "    width_ratios = [2.5]\n",
    "    for i in range(n_profiles):\n",
    "        width_ratios = [1,10] + width_ratios\n",
    "    gs = gridspec.GridSpec(1,2*n_profiles+1, width_ratios=width_ratios)\n",
    "    \n",
    "    figsize = (np.sum(width_ratios)/1.55,6)\n",
    "    fig = plt.figure(figsize=figsize)\n",
    "    \n",
    "    plot_colorbar = False\n",
    "    rotate_x = False\n",
    "    for profile_id in range(n_profiles):\n",
    "        if(profile_id == n_profiles-1):\n",
    "            plot_colorbar = True\n",
    "            rotate_x = True\n",
    "            \n",
    "        plot_cluster_heatmap_on_gridspec(profile_values = profile_values_list[profile_id],\n",
    "                                         labels = labels_list[profile_id],\n",
    "                                         cluster_metric = cluster_metric,\n",
    "                                         linkage_method = linkage_method,\n",
    "                                         score_percentile = score_percentile,\n",
    "                                         gs=gs,\n",
    "                                         gs_from = profile_id*2,\n",
    "                                         clim = clim,\n",
    "                                         rotate_x = rotate_x,\n",
    "                                         plot_colorbar = plot_colorbar)\n",
    "    \n",
    "    if(figure_dir is None):\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    else:\n",
    "        plt.savefig(figure_dir + \"clustering_heatmap_threshold\"+str(score_percentile)+\"_layer\" + str(layer_id).zfill(2) + \".\"+fig_format,\n",
    "                    dpi=300,\n",
    "                    format=fig_format,\n",
    "                    bbox_inches='tight')\n",
    "        plt.close() \n",
    "\n",
    "def score(dists, Z,score_percentile):\n",
    "#     threshold = 0.7*max(Z[:,2]) # default from dendrogram\n",
    "    threshold = np.percentile(Z[:,2],score_percentile)\n",
    "    clusters = hierarchy.fcluster(Z, threshold,'distance')\n",
    "    if(len(np.unique(clusters))==1):\n",
    "        return(0)\n",
    "    else:\n",
    "        return silhouette_score(dists, clusters, metric='precomputed')  \n",
    "    \n",
    "def silhouette_scores(profile_values, cluster_metric='euclidean', linkage_method='complete', score_percentiles=[80]):\n",
    "    distance_mat = pairwise_distances(profile_values,metric=cluster_metric)\n",
    "    linkage = hierarchy.linkage(profile_values, metric=cluster_metric, method=linkage_method, optimal_ordering=False)\n",
    "    silhouettes = np.zeros(len(score_percentiles))\n",
    "    for i, threshold in enumerate(score_percentiles):\n",
    "        silhouettes[i] = score(distance_mat, linkage, threshold)\n",
    "    return(silhouettes)\n",
    "    \n",
    "\n",
    "layers = np.arange(12)\n",
    "score_percentiles = np.arange(75,96,5)\n",
    "\n",
    "silhouettes = np.zeros((2,len(layers),len(score_percentiles)))\n",
    "\n",
    "figure_dir = \"/project/asr_introspection/figures/\"\n",
    "fig_format = \"png\"\n",
    "\n",
    "for l_id, layer_id in enumerate(layers):\n",
    "    norm_acts = normalized_averages[layer_id]['acts']\n",
    "    absgrads = averages[layer_id]['grads']\n",
    "    gradNAPs_flat = np.zeros((len(joint_list),norm_acts.shape[1]*norm_acts.shape[2]))\n",
    "    for char_id in range(len(joint_list)):\n",
    "        if(n_samples[char_id]>0):\n",
    "            gradient_mask = np.abs(absgrads[char_id,:,:]) / np.max(np.abs(absgrads[char_id,:,:]))\n",
    "            gradNAPs_flat[char_id] = np.reshape(norm_acts[char_id,:,:] * gradient_mask,-1)\n",
    "    \n",
    "    gradNAPs_flat_graphemes = gradNAPs_flat[:27,:]\n",
    "    gradNAPs_flat_graphemes = gradNAPs_flat_graphemes/np.max(np.abs(gradNAPs_flat_graphemes))\n",
    "    gradNAPs_flat_phonemes = gradNAPs_flat[28:,:]\n",
    "    gradNAPs_flat_phonemes = gradNAPs_flat_phonemes/np.max(np.abs(gradNAPs_flat_phonemes))\n",
    "    \n",
    "    grapheme_list = joint_list[:27]\n",
    "    for g_id in range(len(grapheme_list)):\n",
    "        grapheme_list[g_id] = grapheme_list[g_id].upper()\n",
    "    phoneme_list = joint_list[28:]\n",
    "    \n",
    "#     for p in score_percentiles:\n",
    "#         plot_cluster_heatmaps(profile_values_list=[gradNAPs_flat_graphemes,gradNAPs_flat_phonemes],\n",
    "#                               labels_list=[grapheme_list,phoneme_list],\n",
    "#                               cluster_metric='euclidean',\n",
    "#                               score_percentile = p,\n",
    "#                               figure_dir = figure_dir,\n",
    "#                               layer_id = layer_id,\n",
    "#                               fig_format = fig_format)\n",
    "\n",
    "    silhouettes[0,l_id,:] = silhouette_scores(gradNAPs_flat_graphemes,score_percentiles=score_percentiles)\n",
    "    silhouettes[1,l_id,:] = silhouette_scores(gradNAPs_flat_phonemes,score_percentiles=score_percentiles)\n",
    "\n",
    "\n",
    "font = {'family' : 'sans',\n",
    "        'weight' : 'regular',\n",
    "        'size'   : 22}\n",
    "mpl.rc('font', **font)\n",
    "\n",
    "titles = ['graphemes','phonemes','averaged']\n",
    "fig = plt.figure(figsize=(16,5))\n",
    "for i in range(3):\n",
    "    plt.subplot(1,3,i+1)\n",
    "    if i<2:\n",
    "        plt.plot(silhouettes[i,:,:],'o-')\n",
    "        plt.legend(score_percentiles,ncol=2,columnspacing=0.5,labelspacing=0,loc='upper left',fontsize=20)\n",
    "    else:\n",
    "        plt.plot(np.transpose(np.mean(silhouettes,2)),'o-')\n",
    "        plt.legend(['graphemes','phonemes'],ncol=1,columnspacing=0.5,labelspacing=0,loc='upper left',fontsize=20)\n",
    "    plt.xlabel('layer')\n",
    "    if(i<1):\n",
    "        plt.ylabel('silhouette score')\n",
    "        plt.yticks(np.arange(0,np.max(silhouettes)+0.05,0.1))\n",
    "    else:\n",
    "        plt.ylabel('')\n",
    "        plt.yticks(np.arange(0,np.max(silhouettes)+0.05,0.1),'')\n",
    "    plt.ylim([0,np.max(silhouettes)+0.05])\n",
    "    xticklabs = ['in']+list(np.array(np.arange(11)+1,'str'))\n",
    "    for j in np.arange(2,11,2):\n",
    "        xticklabs[j] = ''\n",
    "    plt.xticks(range(12),xticklabs)\n",
    "    plt.grid(linestyle='dotted')\n",
    "    ttl = plt.title(titles[i])\n",
    "    ttl.set_position([.5, 1.01])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(figure_dir + \"score_curves.\" +fig_format,\n",
    "        dpi=300,\n",
    "        format=fig_format,\n",
    "        bbox_inches='tight')\n",
    "\n",
    "plt.close()\n",
    "\n",
    "# plt.show()\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['', '1', '', '3', '', '5', '', '7', '', '9', '', '11']"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xticklabs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  2,  4,  6,  8, 10])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.arange(0,11,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "?plt.title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
