{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import librosa\n",
    "import string\n",
    "import numpy as np\n",
    "import pickle\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import colorConverter\n",
    "import tensorflow as tf\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "char_list = list(\" '\" + string.ascii_lowercase + '12 ')\n",
    "\n",
    "def absmax(nd_array):\n",
    "    a = np.max(np.abs(nd_array))\n",
    "    return((-a,a))\n",
    "\n",
    "def elapsed_time(t_start,unit):\n",
    "    t_end = time.time()\n",
    "    d = t_end - t_start\n",
    "    if(unit=='min'):\n",
    "        d /= 60\n",
    "    elif(unit=='h'):\n",
    "        d /= 3600\n",
    "    print('%.2f '%d, unit + ' elapsed',sep='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/data/asr_introspection/w2l_weights.pkl\", \"rb\") as input_file:\n",
    "    weights = pickle.load(input_file)\n",
    "with open(\"/data/asr_introspection/w2l_bn_params.pkl\", \"rb\") as input_file:\n",
    "    bn_params = pickle.load(input_file)\n",
    "\n",
    "responsive_units_array = np.load(\"/data/asr_introspection/responsive_units_array_signed.npy\")\n",
    "\n",
    "data_dir = \"/data/asr_introspection/\"\n",
    "\n",
    "with open(data_dir + \"vocabularies.pkl\", \"rb\") as input_file:\n",
    "    graphemes_list, phonemes_list, _ = pickle.load(input_file)\n",
    "joint_list = graphemes_list + phonemes_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([241, 252,  16, -64,  58], dtype=int32)"
      ]
     },
     "execution_count": 382,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "responsive_units_array[1,5,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(67, 12, 5)\n"
     ]
    }
   ],
   "source": [
    "print(responsive_units_array.shape)\n",
    "# kernel_sizes = [48,7,7,7,7,7,7,7,7,32,1,1]\n",
    "#       strides = [2,1,1,1,1,1,1,1,1, 1,1,1]\n",
    "\n",
    "# r=48\n",
    "# print(r)\n",
    "# for i in range(8):\n",
    "#     r= r+(2*6)\n",
    "#     print(r)\n",
    "# r= r+(2*31)\n",
    "# print(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "' - plot saved\n",
      "a - plot saved\n",
      "b - plot saved\n",
      "c - plot saved\n",
      "d - plot saved\n",
      "e - plot saved\n",
      "f - plot saved\n",
      "g - plot saved\n",
      "h - plot saved\n",
      "i - plot saved\n",
      "j - plot saved\n",
      "k - plot saved\n",
      "l - plot saved\n",
      "m - plot saved\n",
      "n - plot saved\n",
      "o - plot saved\n",
      "p - plot saved\n",
      "q - plot saved\n",
      "s - plot saved\n",
      "t - plot saved\n",
      "u - plot saved\n",
      "v - plot saved\n",
      "w - plot saved\n",
      "x - plot saved\n",
      "y - plot saved\n",
      "z - plot saved\n",
      "AA - plot saved\n",
      "AE - plot saved\n",
      "AH - plot saved\n",
      "AO - plot saved\n",
      "AW - plot saved\n",
      "AY - plot saved\n",
      "B - plot saved\n",
      "CH - plot saved\n",
      "D - plot saved\n",
      "DH - plot saved\n",
      "EH - plot saved\n",
      "ER - plot saved\n",
      "EY - plot saved\n",
      "F - plot saved\n",
      "G - plot saved\n",
      "HH - plot saved\n",
      "IH - plot saved\n",
      "IY - plot saved\n",
      "JH - plot saved\n",
      "K - plot saved\n",
      "L - plot saved\n",
      "M - plot saved\n",
      "N - plot saved\n",
      "NG - plot saved\n",
      "OW - plot saved\n",
      "OY - plot saved\n",
      "P - plot saved\n",
      "R - plot saved\n",
      "S - plot saved\n",
      "SH - plot saved\n",
      "T - plot saved\n",
      "TH - plot saved\n",
      "UH - plot saved\n",
      "UW - plot saved\n",
      "V - plot saved\n",
      "W - plot saved\n",
      "Y - plot saved\n",
      "Z - plot saved\n",
      "ZH - plot saved\n"
     ]
    }
   ],
   "source": [
    "def build_dict(layer_id, input_tensor, weights, bn_params):\n",
    "    d = dict()\n",
    "#     d[input_tensor]=[np.transpose(spec)]\n",
    "    \n",
    "    if layer_id==11:\n",
    "        d['out/bias:0'] = weights[11]\n",
    "        d['out/kernel:0'] = weights[12]\n",
    "        layer_id -= 1\n",
    "    \n",
    "    for i in np.arange(layer_id+1):\n",
    "        d['conv_'+str(i)+'/kernel:0'] = weights[i]\n",
    "        d['batch_norm_'+str(i)+'/beta:0'] = bn_params[(i*4)]\n",
    "        d['batch_norm_'+str(i)+'/gamma:0'] = bn_params[(i*4)+1]\n",
    "        d['batch_norm_'+str(i)+'/moving_mean:0'] = bn_params[(i*4)+2]\n",
    "        d['batch_norm_'+str(i)+'/moving_variance:0'] = bn_params[(i*4)+3]\n",
    "    \n",
    "    return d\n",
    "\n",
    "def conv_layer(inputs, n_filter, kernel_size, stride, layer_id, out_layer=False):\n",
    "    if(not out_layer):\n",
    "        conv = tf.layers.conv1d(\n",
    "            inputs = inputs, \n",
    "            filters = n_filter, \n",
    "            kernel_size = kernel_size,\n",
    "            strides=stride, \n",
    "            activation=None,\n",
    "            use_bias=False, \n",
    "            padding=\"valid\",\n",
    "            name=\"conv_\"+str(layer_id),\n",
    "            data_format=\"channels_last\",\n",
    "            trainable=False)\n",
    "\n",
    "        conv_bn = tf.layers.batch_normalization(\n",
    "            conv, \n",
    "            axis=2, \n",
    "            training=False, \n",
    "            name=\"batch_norm_\"+str(layer_id),\n",
    "            trainable=False)\n",
    "\n",
    "        relu_out = tf.nn.relu(conv_bn)\n",
    "\n",
    "        return(conv_bn,relu_out)\n",
    "    else:\n",
    "        conv = tf.layers.conv1d(\n",
    "            inputs = inputs, \n",
    "            filters = n_filter, \n",
    "            kernel_size = kernel_size,\n",
    "            strides=stride, \n",
    "            activation=None,\n",
    "            use_bias=True, \n",
    "            padding=\"valid\",\n",
    "            name=\"out\",\n",
    "            data_format=\"channels_last\",\n",
    "            trainable=False)\n",
    "\n",
    "        return(conv)\n",
    "\n",
    "def build_w2l_model(weights,bn_params,layer_id,filter_ids):\n",
    "    tf.reset_default_graph()\n",
    "\n",
    "    n_filters = [256,256,256,256,256,256,256,256,256,2048,2048,31]\n",
    "    kernel_sizes = [48,7,7,7,7,7,7,7,7,32,1,1]\n",
    "    strides = [2,1,1,1,1,1,1,1,1,1,1,1]\n",
    "    GRIDS = {16: (4, 4), 32: (8, 4), 64: (8, 8), 128: (16, 8), 256: (16, 16),\n",
    "             512: (32, 16), 1024: (32, 32), 2048: (64, 32), 31: (31,1)}\n",
    "    receptive_field_sizes = [48,60,72,84,96,108,120,132,144,206,206,206]\n",
    "    \n",
    "    x = tf.get_variable(\"x\", [1,206,128], dtype=tf.float32, initializer = tf.initializers.random_normal(mean=0,stddev=0.001))\n",
    "#     x = 5 * (x / tf.reduce_max(tf.abs(x)) )  # spectrogram data is in the range [-4.98,4.64]\n",
    "    \n",
    "    x_perturbated = tf.concat([x for i in range(5)],0) #input robust to n random perturbations\n",
    "    x_perturbated = x_perturbated + tf.random_normal(tf.shape(x_perturbated),mean=0,stddev=0.05)\n",
    "\n",
    "    layer_outs = []\n",
    "    pre_activations = []\n",
    "    p,l = conv_layer(x_perturbated,n_filters[0],kernel_sizes[0],strides[0],0)\n",
    "    pre_activations.append(p)\n",
    "    layer_outs.append(l)\n",
    "\n",
    "    for i in np.arange(11)[1:]:\n",
    "        p,l = conv_layer(layer_outs[i-1],n_filters[i],kernel_sizes[i],strides[i],i)\n",
    "        pre_activations.append(p)\n",
    "        layer_outs.append(l)\n",
    "\n",
    "    pre_activations.append(conv_layer(layer_outs[10],n_filters[11],kernel_sizes[11],strides[11],11,out_layer=True))\n",
    "    layer_outs.append(tf.nn.softmax(pre_activations[11]))\n",
    "    \n",
    "#     loss = layer_outs[layer_id][:,tf.cast(tf.floor(tf.shape(layer_outs[layer_id])[1]/2),tf.int32),:]\n",
    "    loss = layer_outs[layer_id][:,0,:]\n",
    "    loss = tf.reduce_sum(np.sign(filter_ids)*(-1)*tf.reduce_sum(tf.gather(loss,np.abs(filter_ids),axis=1),axis=0))\n",
    "    \n",
    "    # regularization parameters dependent on width of receptive field in the respective layer\n",
    "    loss = loss + tf.contrib.layers.apply_regularization(\n",
    "        regularizer=tf.contrib.layers.l1_l2_regularizer(15 / receptive_field_sizes[layer_id],\n",
    "                                                        0.1 / receptive_field_sizes[layer_id]),\n",
    "        weights_list=[x]\n",
    "    )\n",
    "    \n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate=0.05)\n",
    "    train_op = optimizer.minimize(\n",
    "        loss=loss,\n",
    "        global_step=tf.train.get_global_step())\n",
    "    \n",
    "    return([train_op,x,loss])\n",
    "\n",
    "receptive_field_sizes = [48,60,72,84,96,108,120,132,144,206,206,206]\n",
    "n_steps = 16\n",
    "print_each = 0#np.int(n_steps/5)\n",
    "n_repetitions = 1\n",
    "layers = np.arange(11)\n",
    "characters = np.arange(len(joint_list))\n",
    "\n",
    "figure_dir = \"/project/asr_introspection/figures/\"\n",
    "fig_format = \"pdf\"\n",
    "\n",
    "for char_id in characters:\n",
    "    if(joint_list[char_id] != \" \"):\n",
    "        print(joint_list[char_id],end='')\n",
    "        fig = plt.figure(figsize=(100,5))\n",
    "        grid = plt.GridSpec(1, len(layers), hspace=0.2, wspace=0.2, width_ratios=np.array(receptive_field_sizes)[:-1]/48)\n",
    "        main_ax = fig.add_subplot(grid[0])\n",
    "        main_ax.axis('off')\n",
    "\n",
    "        for l_id, layer_id in enumerate(layers):\n",
    "            tf.reset_default_graph()\n",
    "            ops = build_w2l_model(weights, bn_params, layer_id,responsive_units_array[char_id,layer_id+1,:])\n",
    "            mean_optimal_input = np.zeros([1,206,128])\n",
    "            rep =0\n",
    "            while rep < n_repetitions:\n",
    "                with tf.Session() as sess:\n",
    "                    init = tf.global_variables_initializer()\n",
    "                    sess.run(init)\n",
    "\n",
    "                    d = build_dict(11,None,weights,bn_params)\n",
    "                    for i in range(n_steps):\n",
    "                        if print_each>0 and i%print_each==print_each-1:\n",
    "                            print(str(i+1),end='.')\n",
    "                        _, optimal_input,tracking_loss = sess.run(ops,feed_dict=d)\n",
    "                    mean_optimal_input = mean_optimal_input + optimal_input\n",
    "                    rep += 1\n",
    "                    if rep==n_repetitions and np.max(np.abs(optimal_input))<0.1:\n",
    "                        rep=0\n",
    "    #                     print(\"another round\")\n",
    "        #             print(tracking_loss)\n",
    "            mean_optimal_input = mean_optimal_input / n_repetitions\n",
    "\n",
    "            fig.add_subplot(grid[l_id], sharey=main_ax)\n",
    "        #     plt.subplot(1,len(layers),l_id+1)\n",
    "            plt.imshow(np.transpose(mean_optimal_input[0,:receptive_field_sizes[layer_id],:])[::-1,:],cmap='bwr')\n",
    "            # plt.plot([receptive_field_sizes[layer_id]-1,receptive_field_sizes[layer_id]-1],[0,127],color='black')\n",
    "            plt.clim(absmax(optimal_input[0,:,:]))\n",
    "            plt.colorbar()\n",
    "            plt.yticks([], [])\n",
    "            plt.xticks([], [])\n",
    "    #     plt.show()\n",
    "        plt.savefig(figure_dir + \"visualized_features_char_\"+joint_list[char_id]+\".\"+fig_format,\n",
    "                    dpi=300,\n",
    "                    format=fig_format,\n",
    "                    bbox_inches='tight')\n",
    "        plt.close()\n",
    "        print(\" - plot saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.        , 1.25      , 1.5       , 1.75      , 2.        ,\n",
       "       2.25      , 2.5       , 2.75      , 3.        , 4.29166667,\n",
       "       4.29166667, 4.29166667])"
      ]
     },
     "execution_count": 394,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([48,60,72,84,96,108,120,132,144,206,206,206])/48"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
